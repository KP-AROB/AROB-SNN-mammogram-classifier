{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About BindsNet image to spike encoders\n",
    "\n",
    "This notebook roughly present the BindsNet API behind the conversion of image datasets to spiking datasets. <br />\n",
    "It's called is to build confidence in the development of new encoding methods for Spiking Neural Network input layers creation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BindsNet Dataset Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To encode input pixels to temporal data, BindsNet uses a ```TorchvisionDatasetWrapper``` class that creates **Custom** PyTorch dataset (read more about custom datasets and dataloaders -> [Here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)). <br/>\n",
    "\n",
    "The wrapper extends the ```torch.utils.data.Dataset``` class by adding 2 new parameters - ```image_encoder``` and ```label_encoder```. These encoders are instances of \n",
    "```bindsnet.encoding``` classes (PoissonEncoder, Bernoulli, RankOrderEncoder ...). The encoder classes are then called inside the custom dataset in the ```__getitem__``` function to encode the data once the dataset class is instanciated : \n",
    "\n",
    "\n",
    "```python\n",
    "...\n",
    "def __getitem__(self, ind: int) -> Dict[str, torch.Tensor]:\n",
    "    image, label = super().__getitem__(ind)\n",
    "\n",
    "    output = {\n",
    "        \"image\": image,\n",
    "        \"label\": label,\n",
    "        \"encoded_image\": self.image_encoder(image),\n",
    "        \"encoded_label\": self.label_encoder(label),\n",
    "    }\n",
    "\n",
    "    return output\n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The signature of the encoding functions is as follows : \n",
    "\n",
    "```python\n",
    "def poisson(\n",
    "    datum: torch.Tensor,\n",
    "    time: Optional[int] = None,\n",
    "    dt: float = 1.0,\n",
    "    device=\"cpu\",\n",
    "    **kwargs,\n",
    ") -> torch.Tensor:\n",
    "```\n",
    "\n",
    "They take an input tensor (from ```__getitem__```), the ```time``` window from encoding (250 for 250 ms for example) and ```dt``` as the simulation timestep. So if the encoding was done with a precision of 0.5ms and the time window is 200 then the returned tensor would have a shape of ```(time/dt, 1, image_size, image_size)```.\n",
    "\n",
    "> **_Existing encoders :_** \n",
    "> The framework already provides encoders for poisson rate encoding, time-to-first-spike encoding, rank-order encoding and bernoulli encoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a new encoder class\n",
    "\n",
    "### Burst Coding\n",
    "\n",
    "In [burst coding](https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2021.638474/full), pixels are normalized in the range (0, 1). For an input pixel P, the **number** of spikes in a burst is calculated as $N_{s}(P) = \\lceil N_{max}P \\rceil$, where $N_{max}$ is the maximum number of spikes and $\\lceil . \\rceil$ is the ceiling function. To create the spike train, the inter-spikes interval (ISI) also has to be calculated : \n",
    "\n",
    "$$\n",
    "ISI(P) = \n",
    "\\begin{cases} \n",
    "    \\lceil - (T_{max} - T_{min}) P + T_{max} \\rceil, & N_{s} > 1 \\\\ \n",
    "    T_{max}, & otherwise\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $T_{max}$ and $T_{min}$ are the maximum and minimum intervals, respectively. The ISI is confined in [$T_{min}$,$T_{max}$]. A larger input pixel produces a burst with a smaller ISI and more spikes inside. In the reference paper, the parameters are configured in a biological range. $N_{max}$ is chosen as 5 spikes for the optimal classification and computational performance (on biological base). $T_{max}$ was chosen as the time window for processing one image. $T_{min}$ was taken as 2 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math\n",
    "\n",
    "def burst(\n",
    "    datum: torch.Tensor,\n",
    "    time: int,\n",
    "    dt: float = 1.0,\n",
    "    tmin: int = 2,\n",
    "    nmax: int = 5,\n",
    "    device=\"cpu\",\n",
    "    **kwargs,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generates burst spike trains based on input intensity.\n",
    "\n",
    "    :param datum: Tensor of shape ``[n_1, ..., n_k]``.\n",
    "    :param time: Length of Poisson spike train per input variable.\n",
    "    :param dt: Simulation time step.\n",
    "    :param tmin: int: Minimum spike timing.\n",
    "    :param nmax: int: Maximum number of spike per neuron.\n",
    "    :param device: target destination\n",
    "    :return: Tensor of shape ``[time, n_1, ..., n_k]`` of burst spikes.\n",
    "    \"\"\"\n",
    "    result = datum * nmax\n",
    "    n_spikes = torch.ceil(result).int()\n",
    "    # if n_spikes > 1:\n",
    "    #     ISI = torch.ceil(-(T_max - T_min) * P + T_max)\n",
    "    # else:\n",
    "    #     # Set ISI to T_max if N_s <= 1\n",
    "    #     ISI = T_max\n",
    "    return torch.Tensor(n_spikes).byte()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dt = 1 \n",
    "device = 'cuda'\n",
    "datum = torch.rand(1, 28, 28) * 128\n",
    "shape, size = datum.shape, datum.numel()\n",
    "datum = datum.flatten().to(device)\n",
    "\n",
    "time = int(200 / dt)\n",
    "\n",
    "rate = torch.zeros(size, device=device)\n",
    "rate[datum != 0] = 1 / datum[datum != 0] * (1000 / dt)\n",
    "\n",
    "dist = torch.distributions.Poisson(rate=rate, validate_args=False)\n",
    "intervals = dist.sample(sample_shape=torch.Size([time + 1]))\n",
    "intervals[:, datum != 0] += (intervals[:, datum != 0] == 0).float()\n",
    "\n",
    "times = torch.cumsum(intervals, dim=0).long()\n",
    "times[times >= time + 1] = 0\n",
    "\n",
    "spikes = torch.zeros(time + 1, size, device=device).byte()\n",
    "spikes[times, torch.arange(size)] = 1\n",
    "\n",
    "\n",
    "spikes = spikes[1:]\n",
    "\n",
    "spikes = spikes.view(time, *shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-to-first-spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = torch.rand(1, 28, 28)\n",
    "sparsity = 0.5\n",
    "time = int(time / dt)\n",
    "shape = list(datum.shape)\n",
    "datum = torch.tensor(datum)\n",
    "quantile = torch.quantile(datum, 1 - sparsity)\n",
    "s = torch.zeros([time, *shape], device=device)\n",
    "s[0] = torch.where(datum > quantile, torch.ones(shape), torch.zeros(shape))\n",
    "spikes = torch.Tensor(s).byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Available labels in dataset : {'abnormal': 0, 'normal': 1}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.utils.dataloaders import load_image_folder_dataloader\n",
    "\n",
    "root = \"/home/nvidia/datasets/vindr-mammo-pngs\"\n",
    "image_size = 128\n",
    "intensity = 128\n",
    "time = 100\n",
    "dt = 1\n",
    "\n",
    "t, v = load_image_folder_dataloader(root, 128, 8, time, dt, intensity, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bindsnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
